{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "# Classifiers / pre-processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./quora_duplicate_questions.tsv\", sep='\\t', encoding='utf-8')\n",
    "df = df[~df.question1.isnull() & ~df.question2.isnull() & ~df.is_duplicate.isnull()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1abd0e210>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEXCAYAAAB76ulbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2AAAjCM2AADjiA0AwLj/AvkbT7DgUFi+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1abcecf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "mpl.style.use('fivethirtyeight')\n",
    "plt.xlabel(\"is_duplicate\")\n",
    "(df.is_duplicate.value_counts() / df.is_duplicate.value_counts().sum()).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models settings\n",
    "---\n",
    "### TF-IDF configuration:\n",
    "- grams: unigrams, bigrams\n",
    "- binary: false (so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2)).fit(pd.concat([df.question1, df.question2]))\n",
    "X = tfidf.transform(df.question1) - tfidf.transform(df.question2) # diff matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM performance on 80/20 split w/ TFIDF\n",
      "0.65\t0.64\t0.65\n",
      "acc: 0.64\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "cut = int(X.shape[0] * .8)\n",
    "X_train, y_train = X[:cut], y[:cut]\n",
    "X_test, y_test = X[cut:], y[cut:]\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"LinearSVM performance on 80/20 split w/ TFIDF\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code below commented for \"safety\"\n",
    "# It takes a while to run - did not measure, but roughly 35-40min\n",
    "# Should not be needed to re-run unless some major change was applied\n",
    "\n",
    "def question2vec(question):\n",
    "    return nlp(question).vector\n",
    "\n",
    "# X_question1 = np.array(df.question1.apply(question2vec).tolist())\n",
    "# X_question2 = np.array(df.question2.apply(question2vec).tolist())\n",
    "# X_mean = (X_question1 + X_question2) / 2\n",
    "# X_diff = np.absolute(X_question1 - X_question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "[LibLinear]elapsed 249s\n",
      "LinearSVM performance on 80/20 split w/ mean doc2vec\n",
      "0.69\t0.70\t0.68\n",
      "(array([ 0.72037081,  0.63376127]), array([ 0.87051416,  0.3987146 ]), array([ 0.78835743,  0.48948334]), array([51774, 29096]))\n",
      "acc: 0.70\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "cut = int(X_mean.shape[0] * .8)\n",
    "X_train, y_train = X_mean[:cut], y[:cut]\n",
    "X_test, y_test = X_mean[cut:], y[cut:]\n",
    "svm = LinearSVC(verbose=2)\n",
    "print 'training...'\n",
    "from time import time\n",
    "t0 = time()\n",
    "svm.fit(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"LinearSVM performance on 80/20 split w/ mean doc2vec\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "[LibLinear]elapsed 108s\n",
      "LinearSVM performance on 80/20 split w/ doc2vec-diff\n",
      "0.65\t0.67\t0.64\n",
      "(array([ 0.69692668,  0.55550663]), array([ 0.84401437,  0.34688617]), array([ 0.76345054,  0.42708135]), array([51774, 29096]))\n",
      "acc: 0.67\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "cut = int(X_diff.shape[0] * .8)\n",
    "X_train, y_train = X_diff[:cut], y[:cut]\n",
    "X_test, y_test = X_diff[cut:], y[cut:]\n",
    "svm = LinearSVC(verbose=2)\n",
    "print 'training...'\n",
    "from time import time\n",
    "t0 = time()\n",
    "svm.fit(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"LinearSVM performance on 80/20 split w/ doc2vec-diff\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "elapsed 72s\n",
      "Xgboost performance on 80/20 split w/ TFIDF diff vector\n",
      "0.72\t0.68\t0.61\n",
      "(array([ 0.67517268,  0.79438631]), array([ 0.97608838,  0.16438686]), array([ 0.79821202,  0.27240368]), array([51774, 29096]))\n",
      "acc: 0.68\n"
     ]
    }
   ],
   "source": [
    "def train_xgb(xt, yt):\n",
    "    dtrain = xgb.DMatrix(xt.tocsc(), label=yt)\n",
    "    dtrain.save_binary(\"train.buffer\")\n",
    "    num_round = 10\n",
    "\n",
    "    param = {}\n",
    "    param['nthread'] = 4\n",
    "    param['eval_metric'] = 'auc'\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 4\n",
    "    param['num_class'] = set(yt).__len__()\n",
    "\n",
    "    plst = param.items()\n",
    "    bst = xgb.train(plst, dtrain, num_round)\n",
    "    return bst\n",
    "\n",
    "def pred_xgb(bst, x_ts):\n",
    "    dtest = xgb.DMatrix(x_ts.tocsc())\n",
    "    return np.argmax(bst.predict(dtest), axis=1)\n",
    "\n",
    "y = df.is_duplicate\n",
    "cut = int(X.shape[0] * .8)\n",
    "X_train, y_train = X[:cut], y[:cut]\n",
    "X_test, y_test = X[cut:], y[cut:]\n",
    "t0 = time()\n",
    "print 'training...'\n",
    "bst = train_xgb(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "y_pred = pred_xgb(bst, X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"Xgboost performance on 80/20 split w/ TFIDF diff vector\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "elapsed 163s\n",
      "Xgboost performance on 80/20 split w/ mean doc2vec vectors\n",
      "0.70\t0.70\t0.66\n",
      "(array([ 0.7025857 ,  0.69377652]), array([ 0.92473056,  0.30344377]), array([ 0.79849564,  0.42221797]), array([51774, 29096]))\n",
      "acc: 0.70\n"
     ]
    }
   ],
   "source": [
    "def train_xgb(xt, yt):\n",
    "    dtrain = xgb.DMatrix(xt, label=yt)\n",
    "    dtrain.save_binary(\"train.buffer\")\n",
    "    num_round = 10\n",
    "\n",
    "    param = {}\n",
    "    param['nthread'] = 4\n",
    "    param['eval_metric'] = 'auc'\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 4\n",
    "    param['num_class'] = set(yt).__len__()\n",
    "\n",
    "    plst = param.items()\n",
    "    bst = xgb.train(plst, dtrain, num_round)\n",
    "    return bst\n",
    "\n",
    "def pred_xgb(bst, x_ts):\n",
    "    dtest = xgb.DMatrix(x_ts)\n",
    "    return np.argmax(bst.predict(dtest), axis=1)\n",
    "\n",
    "y = df.is_duplicate\n",
    "cut = int(X_mean.shape[0] * .8)\n",
    "X_train, y_train = X_mean[:cut], y[:cut]\n",
    "X_test, y_test = X_mean[cut:], y[cut:]\n",
    "t0 = time()\n",
    "print 'training...'\n",
    "bst = train_xgb(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "y_pred = pred_xgb(bst, X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"Xgboost performance on 80/20 split w/ mean doc2vec vectors\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "elapsed 168s\n",
      "Xgboost performance on 80/20 split w/ diff doc2vec vectors\n",
      "0.66\t0.68\t0.65\n",
      "(array([ 0.69922819,  0.5927444 ]), array([ 0.87142195,  0.3330011 ]), array([ 0.77588609,  0.4264337 ]), array([51774, 29096]))\n",
      "acc: 0.68\n"
     ]
    }
   ],
   "source": [
    "def train_xgb(xt, yt):\n",
    "    dtrain = xgb.DMatrix(xt, label=yt)\n",
    "    dtrain.save_binary(\"train.buffer\")\n",
    "    num_round = 10\n",
    "\n",
    "    param = {}\n",
    "    param['nthread'] = 4\n",
    "    param['eval_metric'] = 'auc'\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 4\n",
    "    param['num_class'] = set(yt).__len__()\n",
    "\n",
    "    plst = param.items()\n",
    "    bst = xgb.train(plst, dtrain, num_round)\n",
    "    return bst\n",
    "\n",
    "def pred_xgb(bst, x_ts):\n",
    "    dtest = xgb.DMatrix(x_ts)\n",
    "    return np.argmax(bst.predict(dtest), axis=1)\n",
    "\n",
    "y = df.is_duplicate\n",
    "cut = int(X_diff.shape[0] * .8)\n",
    "X_train, y_train = X_diff[:cut], y[:cut]\n",
    "X_test, y_test = X_diff[cut:], y[cut:]\n",
    "t0 = time()\n",
    "print 'training...'\n",
    "bst = train_xgb(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "y_pred = pred_xgb(bst, X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"Xgboost performance on 80/20 split w/ diff doc2vec vectors\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "building tree 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.7s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 25s\n",
      "RandomForest performance 50 estimators on 80/20 split w/ mean tf-idf vector\n",
      "0.77\t0.64\t0.50\n",
      "(array([ 0.64053743,  1.        ]), array([ 1.        ,  0.00140913]), array([ 0.78088731,  0.00281429]), array([51774, 29096]))\n",
      "acc: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "cut = int(X_mean.shape[0] * .8)\n",
    "X_train, y_train = X[:cut], y[:cut]\n",
    "X_test, y_test = X[cut:], y[cut:]\n",
    "rf = RandomForestClassifier(verbose=2, n_estimators=10, max_depth=6)\n",
    "print 'training...'\n",
    "from time import time\n",
    "t0 = time()\n",
    "rf.fit(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"RandomForest performance 50 estimators on 80/20 split w/ mean tf-idf vector\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "building tree 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 125s\n",
      "RandomForest performance 50 estimators on 80/20 split w/ mean doc2vec-diff vector\n",
      "0.66\t0.68\t0.66\n",
      "(array([ 0.70489173,  0.58688012]), array([ 0.85695523,  0.3615961 ]), array([ 0.77352093,  0.44748315]), array([51774, 29096]))\n",
      "acc: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "cut = int(X_diff.shape[0] * .8)\n",
    "X_train, y_train = X_diff[:cut], y[:cut]\n",
    "X_test, y_test = X_diff[cut:], y[cut:]\n",
    "rf = RandomForestClassifier(verbose=2, n_estimators=10)\n",
    "print 'training...'\n",
    "from time import time\n",
    "t0 = time()\n",
    "rf.fit(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"RandomForest performance 50 estimators on 80/20 split w/ mean doc2vec-diff vector\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "building tree 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 145s\n",
      "RandomForest performance 50 estimators on 80/20 split w/ mean doc2vec-mean vector\n",
      "0.74\t0.75\t0.73\n",
      "(array([ 0.75534843,  0.71433616]), array([ 0.89062077,  0.4866992 ]), array([ 0.81742599,  0.57894522]), array([51774, 29096]))\n",
      "acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "cut = int(X_mean.shape[0] * .8)\n",
    "X_train, y_train = X_mean[:cut], y[:cut]\n",
    "X_test, y_test = X_mean[cut:], y[cut:]\n",
    "rf = RandomForestClassifier(verbose=2, n_estimators=10)\n",
    "print 'training...'\n",
    "from time import time\n",
    "t0 = time()\n",
    "rf.fit(X_train, y_train)\n",
    "t0 = time() - t0\n",
    "print 'elapsed %.0fs' % t0\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"RandomForest performance 50 estimators on 80/20 split w/ mean doc2vec-mean vector\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input (InputLayer)               (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 50)            15050       input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 2)             102         dense_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 15152\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(300,), name='input')\n",
    "x = Dense(50, activation='relu')(input_)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "model = Model(input_, output, name='mlp')\n",
    "model.compile('adagrad', 'binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "323479/323479 [==============================] - 31s - loss: 0.5608    \n",
      "Epoch 2/5\n",
      "323479/323479 [==============================] - 31s - loss: 0.5523    \n",
      "Epoch 3/5\n",
      "323479/323479 [==============================] - 30s - loss: 0.5469    \n",
      "Epoch 4/5\n",
      "323479/323479 [==============================] - 29s - loss: 0.5428    \n",
      "Epoch 5/5\n",
      "323479/323479 [==============================] - 30s - loss: 0.5396    \n",
      "MLP performance 1 hidden layer 5 epochs on 80/20 split w/ doc2vec-mean vector\n",
      "0.73\t0.73\t0.72\n",
      "(array([ 0.75325504,  0.67498946]), array([ 0.86599451,  0.49522271]), array([ 0.80570006,  0.5712983 ]), array([51774, 29096]))\n",
      "acc: 0.73\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "y = np.array(y.apply(lambda x: (1, 0) if x == 0 else (0, 1)).tolist())\n",
    "\n",
    "cut = int(X_mean.shape[0] * .8)\n",
    "X_train, y_train = X_mean[:cut], y[:cut]\n",
    "X_test, y_test = X_mean[cut:], y[cut:].argmax(axis=1)\n",
    "\n",
    "hist = model.fit(X_train, y_train, nb_epoch=5, verbose=1)\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"MLP performance 1 hidden layer 5 epochs on 80/20 split w/ doc2vec-mean vector\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "323479/323479 [==============================] - 33s - loss: 0.5924    \n",
      "Epoch 2/5\n",
      "323479/323479 [==============================] - 30s - loss: 0.5723    \n",
      "Epoch 3/5\n",
      "323479/323479 [==============================] - 31s - loss: 0.5690    \n",
      "Epoch 4/5\n",
      "323479/323479 [==============================] - 34s - loss: 0.5676    \n",
      "Epoch 5/5\n",
      "323479/323479 [==============================] - 37s - loss: 0.5668    \n",
      "MLP performance 1 hidden layer 5 epochs on 80/20 split w/ doc2vec-diff vector\n",
      "0.69\t0.69\t0.69\n",
      "(array([ 0.74647603,  0.57920867]), array([ 0.78554873,  0.5252612 ]), array([ 0.76551413,  0.55091741]), array([51774, 29096]))\n",
      "acc: 0.69\n"
     ]
    }
   ],
   "source": [
    "y = df.is_duplicate\n",
    "y = np.array(y.apply(lambda x: (1, 0) if x == 0 else (0, 1)).tolist())\n",
    "\n",
    "cut = int(X_diff.shape[0] * .8)\n",
    "X_train, y_train = X_diff[:cut], y[:cut]\n",
    "X_test, y_test = X_diff[cut:], y[cut:].argmax(axis=1)\n",
    "\n",
    "hist = model.fit(X_train, y_train, nb_epoch=5, verbose=1)\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "p, r, f, _ = prfs(y_test, y_pred, average='weighted')\n",
    "print \"MLP performance 1 hidden layer 5 epochs on 80/20 split w/ doc2vec-diff vector\"\n",
    "print \"%.2f\\t%.2f\\t%.2f\" % (p, r, f)\n",
    "print prfs(y_test, y_pred)\n",
    "print \"acc: %.2f\" % acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
